{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SC990987/SummerResearch2022/blob/main/QG_SACAMPBELL_Rev1_AddedKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Extract Data\n"
      ],
      "metadata": {
        "id": "Z5EjzsRaVZJd"
      },
      "id": "Z5EjzsRaVZJd"
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir data/"
      ],
      "metadata": {
        "id": "Rp0T0PqlVibO"
      },
      "id": "Rp0T0PqlVibO",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cernbox.cern.ch/index.php/s/ZUHveJKajnZNwTA/download -O data/ZUHveJKajnZNwTA.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoJ-0K4YVljT",
        "outputId": "7c8a7c78-fa5d-4ce1-ff1a-ca5c7ba3e1ea"
      },
      "id": "hoJ-0K4YVljT",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-07 18:12:45--  https://cernbox.cern.ch/index.php/s/ZUHveJKajnZNwTA/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.53.35, 128.142.53.28, 137.138.120.151, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.53.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/ZUHveJKajnZNwTA.tar’\n",
            "\n",
            "data/ZUHveJKajnZNwT     [             <=>    ]   4.51G  22.5MB/s    in 3m 56s  \n",
            "\n",
            "2022-08-07 18:16:49 (19.6 MB/s) - ‘data/ZUHveJKajnZNwTA.tar’ saved [4848198144]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc2hT4B0VnnR",
        "outputId": "b37c5f27-03de-4fff-96c3-98602debdec2"
      },
      "id": "nc2hT4B0VnnR",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "my_tar = tarfile.open('ZUHveJKajnZNwTA.tar')\n",
        "my_tar.extractall('./data') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "metadata": {
        "id": "48r6j4jkVpcu"
      },
      "id": "48r6j4jkVpcu",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data"
      ],
      "metadata": {
        "id": "TNw5kR0eVrxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687bc1fe-2d80-4427-d278-47c0c1ee4287"
      },
      "id": "TNw5kR0eVrxB",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Data Into Images\n"
      ],
      "metadata": {
        "id": "zEXsjkfhVuzZ"
      },
      "id": "zEXsjkfhVuzZ"
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1g_anrPXNsM",
        "outputId": "58ee9381-2da4-4082-fbc1-a2b0bc397155"
      },
      "id": "-1g_anrPXNsM",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pyarrow.parquet as pq\n",
        "import os\n",
        "import time as time\n",
        "import PIL.Image as imm\n",
        "path = \"/content/data\"\n",
        "import cv2"
      ],
      "metadata": {
        "id": "X_OfCwq3Vzqd"
      },
      "id": "X_OfCwq3Vzqd",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"./Images/0\")\n",
        "os.makedirs(\"./Images/1\")"
      ],
      "metadata": {
        "id": "Jpr7DOo-o46P"
      },
      "id": "Jpr7DOo-o46P",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./Images/\""
      ],
      "metadata": {
        "id": "qCuzr2ltNqR0"
      },
      "id": "qCuzr2ltNqR0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(pf):\n",
        "    record_batch = pf.iter_batches(batch_size=1024)\n",
        "    while(True):\n",
        "        try:\n",
        "            batch = next(record_batch)\n",
        "            print(batch.num_rows)\n",
        "            transform(batch)\n",
        "        except StopIteration:\n",
        "            print(\"Done\")\n",
        "            break"
      ],
      "metadata": {
        "id": "FxAJxUQpV3h4"
      },
      "id": "FxAJxUQpV3h4",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0\n",
        "beta =  0\n",
        "def saver(im,meta):\n",
        "    global alpha\n",
        "    global beta\n",
        "    for i in range(meta.shape[0]):\n",
        "        img = im[i,:,:,:]\n",
        "        img = img.T\n",
        "        img[:,:,0] = ( img[:,:,0] - img[:,:,0].min() ) / ( img[:,:,0].max()-img[:,:,0].min() )\n",
        "        img[:,:,1] = ( img[:,:,1] - img[:,:,1].min() ) / ( img[:,:,1].max()-img[:,:,1].min() )\n",
        "        img[:,:,2] = ( img[:,:,2] - img[:,:,2].min() ) / ( img[:,:,2].max()-img[:,:,2].min() )\n",
        "        img = img*255\n",
        "        img = img.astype(np.uint8)\n",
        "        #lmm = imm.fromarray(img)\n",
        "        if(meta[i] == 0):\n",
        "            impath = path+\"1/\"+str(alpha)+\".png\"\n",
        "            alpha = alpha + 1\n",
        "        if(meta[i] == 1):\n",
        "            impath = path+\"0/\"+str(beta)+\".png\"\n",
        "            beta = beta + 1\n",
        "        #lmm.save(impath)\n",
        "        cv2.imwrite(impath , img)"
      ],
      "metadata": {
        "id": "APW54ZLwV4Tb"
      },
      "id": "APW54ZLwV4Tb",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(batch):\n",
        "    p = batch.to_pandas()\n",
        "    im = np.array(np.array(np.array(p.iloc[:,0].tolist()).tolist()).tolist())\n",
        "    meta = np.array(p.iloc[:,3])\n",
        "    saver(im,meta)"
      ],
      "metadata": {
        "id": "K4G0x9hJV6-O"
      },
      "id": "K4G0x9hJV6-O",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(pq.ParquetFile(\"QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet\"))\n",
        "generate(pq.ParquetFile(\"QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet\"))\n",
        "generate(pq.ParquetFile(\"QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWRGrCwnV81B",
        "outputId": "7f740dbf-d280-4a4b-bb07-ec03dcccdd82"
      },
      "id": "nWRGrCwnV81B",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "432\n",
            "Done\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "436\n",
            "Done\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "198\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing (Pytorch)"
      ],
      "metadata": {
        "id": "7FUx_y3sWB2X"
      },
      "id": "7FUx_y3sWB2X"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import os, glob\n",
        "import time\n",
        "import h5py\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import ConcatDataset, Dataset, DataLoader, sampler, DistributedSampler\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import *\n",
        "import numpy\n",
        "import time\n",
        "import h5py\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import math \n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "x5yINiGOWHcF"
      },
      "id": "x5yINiGOWHcF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParquetDataset(Dataset):\n",
        "    def __init__(self, filename, transform=None):\n",
        "        self.parquet = pq.ParquetFile(filename)\n",
        "        self.cols = None \n",
        "        self.transform = transform\n",
        "    def __getitem__(self, index):\n",
        "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
        "        # Preprocessing\n",
        "        start = time.time()\n",
        "        data['X_jets'] = np.float32(data['X_jets'])\n",
        "        data['X_jets'] = torch.Tensor(data['X_jets'])\n",
        "        data['y'] = torch.Tensor(data['y'])\n",
        "        \n",
        "        #to preprocess\n",
        "        data['X_jets'][data['X_jets'] < 1.e-3] = 0. # Zero-Suppression\n",
        "        data['X_jets'][-1,...] = 25.*data['X_jets'][-1,...] # For HCAL: to match pixel intensity distn of other layers\n",
        "        data['X_jets'] = data['X_jets']/100. # To standardize\n",
        "        #data['X'] = np.float32(data['X'][0])\n",
        "        #print(\"List lenth\",data['X_jets'])\n",
        "        #data['X_jets'] = numpy.array(data['X_jets'])\n",
        "        \n",
        "        if self.transform:\n",
        "            #data['X_jets'] = numpy.moveaxis(data['X_jets'], 1,3)\n",
        "            #print(\"Trnsforn : \",data['X_jets'].shape)\n",
        "            data['X_jets']= self.transform(data['X_jets'][0]) \n",
        "        #data['X_jets'] = numpy.moveaxis(data['X_jets'], -1,1)\n",
        "        \n",
        "        #print(\"Lter : \",data['X_jets'].shape)\n",
        "        \n",
        "        end = time.time()\n",
        "        #print(\"Time required for preprocessing : \",end - start)\n",
        "        \n",
        "        #print(\"Mean : \", torch.mean(data['X_jets']))\n",
        "        return dict(data)\n",
        "    def __len__(self):\n",
        "        return self.parquet.num_row_groups"
      ],
      "metadata": {
        "id": "PrY-TMYiWKrn"
      },
      "id": "PrY-TMYiWKrn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "def get_data_loader(datasets, batch_size, cut, random_sampler=False):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.RandomRotation(20)\n",
        "    ])\n",
        "    #scripted_transforms = torch.jit.script(transforms)\n",
        "  \n",
        "    dset = ConcatDataset([ParquetDataset(dataset, transform=transform) for dataset in datasets])\n",
        "    idxs = np.random.permutation(len(dset))\n",
        "    if random_sampler: \n",
        "        random_sampler = sampler.SubsetRandomSampler(idxs[:cut])\n",
        "    else: \n",
        "        random_sampler = None \n",
        "    validation_split = .2\n",
        "    shuffle_dataset = True\n",
        "    random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "    dataset_size = 55494\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    print(split)\n",
        "    if shuffle_dataset :\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(val_indices)\n",
        "    print(\"Train indices \",train_sampler)\n",
        "    print(\"Test indices \", valid_sampler)\n",
        "    train_loader = torch.utils.data.DataLoader(dset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "    test_loader = torch.utils.data.DataLoader(dset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "    \n",
        "    #data_loader = DataLoader(dataset=dset, batch_size=batch_size, shuffle=False, num_workers=10, sampler=random_sampler, pin_memory=True)\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "uDvXzHzrWOSw"
      },
      "id": "uDvXzHzrWOSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_train = ['QCDToGGQQ_IMGjet_RH1all_jet0_run0_n215556.train.snappy.parquet', \n",
        "                  'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n297980.train.snappy.parquet', \n",
        "                  'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n280364.train.snappy.parquet']\n",
        "datasets_test = ['QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet',\n",
        "                 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet',\n",
        "                 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet']"
      ],
      "metadata": {
        "id": "BQyNDvVZWSCN"
      },
      "id": "BQyNDvVZWSCN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data/data"
      ],
      "metadata": {
        "id": "6oznZGn2WUTJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e17c7ce3-bd99-4967-ce72-4c9e5e529ce8"
      },
      "id": "6oznZGn2WUTJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader= get_data_loader(datasets_train, 32, cut = None, random_sampler = True)\n",
        "#test_loader = get_data_loader(datasets_test, 32, cut = None, random_sampler = True)"
      ],
      "metadata": {
        "id": "QjUd39UUWWkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed065a39-8e7e-46ea-e88c-725f7866094e"
      },
      "id": "QjUd39UUWWkk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11098\n",
            "Train indices  <torch.utils.data.sampler.SubsetRandomSampler object at 0x7fa306872e50>\n",
            "Test indices  <torch.utils.data.sampler.SubsetRandomSampler object at 0x7fa306872590>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_loader):\n",
        "    X_jets,\tpt,\tm0,\ty = batch[\"X_jets\"], batch[\"pt\"], batch[\"m0\"],batch[\"y\"]\n",
        "    #print(torch.max(X_jets))\n",
        "    if (i%50 ==0):\n",
        "        print(torch.max(X_jets))"
      ],
      "metadata": {
        "id": "kiPOpwQMWZCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59fbecd8-c2a5-4dfc-a0b9-6be84724da53"
      },
      "id": "kiPOpwQMWZCy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(61.3017)\n",
            "tensor(123.9118)\n",
            "tensor(85.9522)\n",
            "tensor(70.9921)\n",
            "tensor(63.5722)\n",
            "tensor(71.1913)\n",
            "tensor(76.9099)\n",
            "tensor(67.4820)\n",
            "tensor(103.7840)\n",
            "tensor(282.7818)\n",
            "tensor(67.6818)\n",
            "tensor(96.1544)\n",
            "tensor(94.8591)\n",
            "tensor(76.1987)\n",
            "tensor(53.1465)\n",
            "tensor(136.4543)\n",
            "tensor(84.2105)\n",
            "tensor(58.4805)\n",
            "tensor(61.8126)\n",
            "tensor(71.4254)\n",
            "tensor(72.6430)\n",
            "tensor(66.9177)\n",
            "tensor(71.6387)\n",
            "tensor(35.5399)\n",
            "tensor(115.7959)\n",
            "tensor(40.2482)\n",
            "tensor(69.3265)\n",
            "tensor(59.3713)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_collate(batch):\n",
        "    data = torch.cat([item[0] for item in batch],dim = 0)\n",
        "    target = torch.cat([item[1] for item in batch],dim = 0)\n",
        "\n",
        "    return [data, target]"
      ],
      "metadata": {
        "id": "8vTQTkDMWbg7"
      },
      "id": "8vTQTkDMWbg7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, data_loader, loss_history):\n",
        "    total_samples = len(data_loader)*32 #batch size =32\n",
        "    correct_samples = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i, batch in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data = batch[\"X_jets\"]\n",
        "        data = data.cuda()\n",
        "        output = model(data)\n",
        "        target = batch[\"y\"]\n",
        "        target = target.cuda()\n",
        "        target = torch.squeeze(target, dim=1)\n",
        "        loss = nn.BCEWithLogitsLoss()(torch.squeeze(output, dim=1),target)\n",
        "        pred = torch.squeeze(nn.Sigmoid()(output))\n",
        "        pred[pred>=0.5] = 1\n",
        "        pred[pred<0.5] = 0\n",
        "        optimizer.step()\n",
        "        \n",
        "        correct_samples += pred.eq(target).sum()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
        "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\n",
        "                  '{:6.4f}'.format(loss.item()) + '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "                  '{:5}'.format(total_samples) + ' (' + '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)')\n",
        "            loss_history.append(loss.item())"
      ],
      "metadata": {
        "id": "og7QEi3fWd6R"
      },
      "id": "og7QEi3fWd6R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, loss_history):\n",
        "    model.eval()\n",
        "    \n",
        "    total_samples = len(data_loader)*32 #len(data_loader.dataset)\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            \n",
        "            data = batch[\"X_jets\"]\n",
        "            data = data.cuda()\n",
        "            output = model(data)\n",
        "            target = batch[\"y\"]\n",
        "            target = target.cuda()\n",
        "            target = torch.squeeze(target, dim=1)\n",
        "            loss = nn.BCEWithLogitsLoss()(torch.squeeze(output, dim=1),target)\n",
        "            pred = torch.squeeze(nn.Sigmoid()(output))\n",
        "            pred[pred>=0.5] = 1\n",
        "            pred[pred<0.5] = 0\n",
        "            total_loss += loss.item()\n",
        "            correct_samples += pred.eq(target).sum()\n",
        "\n",
        "    avg_loss = total_loss / (total_samples/32)\n",
        "    loss_history.append(avg_loss) \n",
        "    print('\\nAverage val loss: ' + '{:.4f}'.format(avg_loss) +\n",
        "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "          '{:5}'.format(total_samples) + ' (' +\n",
        "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
      ],
      "metadata": {
        "id": "OeybrbsoWgu9"
      },
      "id": "OeybrbsoWgu9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection, Training, and Evaluation (Pytorch)"
      ],
      "metadata": {
        "id": "BThw1UXQWlgc"
      },
      "id": "BThw1UXQWlgc"
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torchvision.models import ResNet18_Weights\n",
        "torchvision.models.ResNet18_Weights(ResNet18_Weights.DEFAULT)\n",
        "#resnet18 = models.resnet18(weights='IMAGENET1K_V1')\n",
        "resnet18 = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "3MvNm9XHWrna",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "ce1a6659239746298055606295f17184",
            "e3eeaab198774ab098dbe00bce553da0",
            "12289f7518d841868b12574219a6671c",
            "1447d20c1b684e579fa25b2c526eb126",
            "4dbda994984f47b2b212806610042426",
            "edf4b36fc3c24f76a35db489a4b2e096",
            "3e28555b9bcc43a687ed792be71eaac2",
            "17c4e81bddeb4ac4a368fc00a02111de",
            "46be4aba70ff467aaae6edaeb3c4f76d",
            "96d29be7de00445494c1592bfaa46b06",
            "f260d32ed54941fc9108166d62800f7c"
          ]
        },
        "outputId": "f9946f8d-da28-4dd2-a026-e73ab4400d67"
      },
      "id": "3MvNm9XHWrna",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce1a6659239746298055606295f17184"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 8\n",
        "import time\n",
        "start_time = time.time()\n",
        "from torch import nn\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "model = resnet18\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "model.fc = nn.Sequential(nn.AdaptiveAvgPool1d(512),\n",
        "                         nn.Dropout(0.3),\n",
        "                         nn.Linear(512,256),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(0.3),\n",
        "                         nn.Linear(256,1),\n",
        "                         nn.Sigmoid())\n",
        "model.cuda()\n",
        "\n",
        "cnt = 0\n",
        "train_loss_history, test_loss_history = [], []\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    \n",
        "    r = 0.0005/(10**(cnt))\n",
        "    print(\"LR:\",r)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=r)\n",
        "    print('Epoch:', epoch)\n",
        "    train_epoch(model, optimizer, train_loader, train_loss_history)\n",
        "    print(\"Training done!\")\n",
        "    evaluate(model, test_loader, test_loss_history)\n",
        "    pred_list, target_list = evaluate(model, test_loader, test_loss_history)\n",
        "    fpr, tpr = roc_curve(target_list, pred_list)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print('Training ROC AUC:', roc_auc)\n",
        "    if epoch%4==0:\n",
        "      cnt=cnt+1\n",
        "    \n",
        "\n",
        "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
      ],
      "metadata": {
        "id": "QZvd6QBKWtjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "ccff8f00-29ac-416f-e6f6-5dc95f0142a2"
      },
      "id": "QZvd6QBKWtjG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR: 0.0005\n",
            "Epoch: 1\n",
            "[    0/44416 (  0%)]  Loss: 0.7515  Accuracy:   15/44416 (0.03%)\n",
            "[ 3200/44416 (  7%)]  Loss: 0.6975  Accuracy: 1579/44416 (3.56%)\n",
            "[ 6400/44416 ( 14%)]  Loss: 0.6463  Accuracy: 3208/44416 (7.22%)\n",
            "[ 9600/44416 ( 22%)]  Loss: 0.7541  Accuracy: 4803/44416 (10.81%)\n",
            "[12800/44416 ( 29%)]  Loss: 0.7664  Accuracy: 6396/44416 (14.40%)\n",
            "[16000/44416 ( 36%)]  Loss: 0.7962  Accuracy: 8001/44416 (18.01%)\n",
            "[19200/44416 ( 43%)]  Loss: 0.7370  Accuracy: 9609/44416 (21.63%)\n",
            "[22400/44416 ( 50%)]  Loss: 0.6639  Accuracy:11221/44416 (25.26%)\n",
            "[25600/44416 ( 58%)]  Loss: 0.7170  Accuracy:12805/44416 (28.83%)\n",
            "[28800/44416 ( 65%)]  Loss: 0.6403  Accuracy:14400/44416 (32.42%)\n",
            "[32000/44416 ( 72%)]  Loss: 0.7216  Accuracy:15984/44416 (35.99%)\n",
            "[35200/44416 ( 79%)]  Loss: 0.7236  Accuracy:17598/44416 (39.62%)\n",
            "[38400/44416 ( 86%)]  Loss: 0.7387  Accuracy:19162/44416 (43.14%)\n",
            "[41600/44416 ( 94%)]  Loss: 0.7532  Accuracy:20815/44416 (46.86%)\n",
            "Training done!\n",
            "\n",
            "Average val loss: 0.7293  Accuracy: 5553/11104 (50.01%)\n",
            "\n",
            "\n",
            "Average val loss: 0.7293  Accuracy: 5553/11104 (50.01%)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-13118f61e187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mpred_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader, loss_history):\n",
        "    model.eval()\n",
        "    pred_list = []\n",
        "    target_list = []\n",
        "    total_samples = len(data_loader)*32\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            \n",
        "            data = batch[\"X_jets\"]\n",
        "            data = data.cuda()\n",
        "            output = model(data)\n",
        "            target = batch[\"y\"]\n",
        "            target = target.cuda()          \n",
        "            target = torch.squeeze(target, dim=1)\n",
        "            loss = nn.BCEWithLogitsLoss()(torch.squeeze(output, dim=1),target)\n",
        "            pred = torch.squeeze(nn.Sigmoid()(output))\n",
        "            pred_list.extend(pred.tolist())\n",
        "            target_list.extend(target.tolist())\n",
        "            pred[pred>=0.5] = 1\n",
        "            pred[pred<0.5] = 0\n",
        "            total_loss += loss.item()\n",
        "            correct_samples += pred.eq(target).sum()\n",
        "\n",
        "    avg_loss = total_loss / (total_samples/32)\n",
        "    loss_history.append(avg_loss)\n",
        "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
        "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "          '{:5}'.format(total_samples) + ' (' +\n",
        "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')\n",
        "    return pred_list,target_list"
      ],
      "metadata": {
        "id": "C2jeaeyQWwbw"
      },
      "id": "C2jeaeyQWwbw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_history = []\n",
        "pred_list, target_list = test(model, test_loader, test_loss_history)"
      ],
      "metadata": {
        "id": "uu2vdXGOWzSO"
      },
      "id": "uu2vdXGOWzSO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, _ = roc_curve(target_list, pred_list)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('Test ROC AUC:', roc_auc)"
      ],
      "metadata": {
        "id": "zkxxb4ogW1Zj"
      },
      "id": "zkxxb4ogW1Zj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "#plt.legend(loc=2, prop={'size': 15})\n",
        "plt.plot(fpr, tpr, label='Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve: Resnet 18 (modified FC Layer)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "plt.savefig('resnet_18_ROC_modified.png')"
      ],
      "metadata": {
        "id": "NFvTkvvbW3eg"
      },
      "id": "NFvTkvvbW3eg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing (Keras)"
      ],
      "metadata": {
        "id": "1lp1oZF9gs8h"
      },
      "id": "1lp1oZF9gs8h"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL.Image as im\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "nB3RrM5UgzAB"
      },
      "id": "nB3RrM5UgzAB",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen= ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/data/Images',\n",
        "        target_size= (125,125),\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "        shuffle = True\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/content/data/data/Images',\n",
        "        target_size= (125,125),\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation',\n",
        "        shuffle = True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zA1Kw3ug1gW",
        "outputId": "61577eb4-e520-485f-9c12-a93498566a66"
      },
      "id": "5zA1Kw3ug1gW",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 111446 images belonging to 2 classes.\n",
            "Found 27860 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection, Training, and Evaluation (Keras)"
      ],
      "metadata": {
        "id": "qze1omIkhGpU"
      },
      "id": "qze1omIkhGpU"
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.resnet50.ResNet50(input_shape= (125,125,3), \n",
        "                                                  weights  = \"imagenet\",\n",
        "                                                  include_top = False\n",
        "                                                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_1sZ3kLhMmE",
        "outputId": "c23271cc-f35b-475e-adc3-782a7679ddf2"
      },
      "id": "6_1sZ3kLhMmE",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 2s 0us/step\n",
            "94781440/94765736 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = True"
      ],
      "metadata": {
        "id": "FBv34VLxhPqh"
      },
      "id": "FBv34VLxhPqh",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(125,125,3))\n",
        "x = tf.keras.layers.RandomFlip()(inputs)\n",
        "x = tf.keras.layers.RandomRotation(0.2)(x)\n",
        "x = base_model(x, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "x = tf.keras.layers.Dense(256 , activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "HU25owvuhR41"
      },
      "id": "HU25owvuhR41",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q -U tensorflow_addons"
      ],
      "metadata": {
        "id": "Hh6T-ojYjmUA"
      },
      "id": "Hh6T-ojYjmUA",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_addons.optimizers import CyclicalLearningRate\n",
        "cyclical_learning_rate = CyclicalLearningRate(\n",
        " initial_learning_rate=1e-6,\n",
        " maximal_learning_rate=1e-3,\n",
        " step_size=1000*6,\n",
        " scale_fn=lambda x: 1 / (2.0 ** (x - 1)),\n",
        " scale_mode='cycle')"
      ],
      "metadata": {
        "id": "ow2Pok_qhT_F"
      },
      "id": "ow2Pok_qhT_F",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=cyclical_learning_rate ,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07\n",
        "),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[tf.keras.metrics.AUC(name = \"auc\")]\n",
        ")"
      ],
      "metadata": {
        "id": "v_sZHY1whXMu"
      },
      "id": "v_sZHY1whXMu",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"./cp_{epoch}_.ckpt\",\n",
        "    monitor='val_auc',\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    mode='auto',\n",
        "    save_freq = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "p_ndYJYmhZ4K"
      },
      "id": "p_ndYJYmhZ4K",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "        train_generator,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps = 500,\n",
        "        epochs=200,\n",
        "        steps_per_epoch = 1000,\n",
        "        verbose = 2,\n",
        "        callbacks = [checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EKw2I2FhcRP",
        "outputId": "f9bd8527-33a1-4841-a06b-a948b0c70d7c"
      },
      "id": "7EKw2I2FhcRP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\n",
            "Epoch 1: saving model to ./cp_1_.ckpt\n",
            "1000/1000 - 172s - loss: 0.6507 - auc: 0.6995 - val_loss: 0.5928 - val_auc: 0.7535 - 172s/epoch - 172ms/step\n",
            "Epoch 2/200\n",
            "\n",
            "Epoch 2: saving model to ./cp_2_.ckpt\n",
            "1000/1000 - 157s - loss: 0.6033 - auc: 0.7442 - val_loss: 0.5905 - val_auc: 0.7558 - 157s/epoch - 157ms/step\n",
            "Epoch 3/200\n",
            "\n",
            "Epoch 3: saving model to ./cp_3_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5982 - auc: 0.7483 - val_loss: 0.5951 - val_auc: 0.7526 - 159s/epoch - 159ms/step\n",
            "Epoch 4/200\n",
            "\n",
            "Epoch 4: saving model to ./cp_4_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5957 - auc: 0.7507 - val_loss: 0.5910 - val_auc: 0.7555 - 159s/epoch - 159ms/step\n",
            "Epoch 5/200\n",
            "\n",
            "Epoch 5: saving model to ./cp_5_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5951 - auc: 0.7519 - val_loss: 0.5972 - val_auc: 0.7604 - 159s/epoch - 159ms/step\n",
            "Epoch 6/200\n",
            "\n",
            "Epoch 6: saving model to ./cp_6_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5930 - auc: 0.7540 - val_loss: 0.5857 - val_auc: 0.7621 - 159s/epoch - 159ms/step\n",
            "Epoch 7/200\n",
            "\n",
            "Epoch 7: saving model to ./cp_7_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5880 - auc: 0.7595 - val_loss: 0.5857 - val_auc: 0.7645 - 159s/epoch - 159ms/step\n",
            "Epoch 8/200\n",
            "\n",
            "Epoch 8: saving model to ./cp_8_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5861 - auc: 0.7614 - val_loss: 0.5838 - val_auc: 0.7670 - 159s/epoch - 159ms/step\n",
            "Epoch 9/200\n",
            "\n",
            "Epoch 9: saving model to ./cp_9_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5802 - auc: 0.7666 - val_loss: 0.5701 - val_auc: 0.7792 - 156s/epoch - 156ms/step\n",
            "Epoch 10/200\n",
            "\n",
            "Epoch 10: saving model to ./cp_10_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5734 - auc: 0.7738 - val_loss: 0.5745 - val_auc: 0.7740 - 158s/epoch - 158ms/step\n",
            "Epoch 11/200\n",
            "\n",
            "Epoch 11: saving model to ./cp_11_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5693 - auc: 0.7777 - val_loss: 0.5633 - val_auc: 0.7825 - 159s/epoch - 159ms/step\n",
            "Epoch 12/200\n",
            "\n",
            "Epoch 12: saving model to ./cp_12_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5655 - auc: 0.7806 - val_loss: 0.5632 - val_auc: 0.7825 - 159s/epoch - 159ms/step\n",
            "Epoch 13/200\n",
            "\n",
            "Epoch 13: saving model to ./cp_13_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5633 - auc: 0.7826 - val_loss: 0.5625 - val_auc: 0.7846 - 156s/epoch - 156ms/step\n",
            "Epoch 14/200\n",
            "\n",
            "Epoch 14: saving model to ./cp_14_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5634 - auc: 0.7829 - val_loss: 0.5633 - val_auc: 0.7834 - 158s/epoch - 158ms/step\n",
            "Epoch 15/200\n",
            "\n",
            "Epoch 15: saving model to ./cp_15_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5678 - auc: 0.7788 - val_loss: 0.5660 - val_auc: 0.7797 - 158s/epoch - 158ms/step\n",
            "Epoch 16/200\n",
            "\n",
            "Epoch 16: saving model to ./cp_16_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5692 - auc: 0.7776 - val_loss: 0.5665 - val_auc: 0.7820 - 158s/epoch - 158ms/step\n",
            "Epoch 17/200\n",
            "\n",
            "Epoch 17: saving model to ./cp_17_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5754 - auc: 0.7717 - val_loss: 0.5638 - val_auc: 0.7822 - 156s/epoch - 156ms/step\n",
            "Epoch 18/200\n",
            "\n",
            "Epoch 18: saving model to ./cp_18_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5720 - auc: 0.7753 - val_loss: 0.5646 - val_auc: 0.7823 - 156s/epoch - 156ms/step\n",
            "Epoch 19/200\n",
            "\n",
            "Epoch 19: saving model to ./cp_19_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5726 - auc: 0.7745 - val_loss: 0.5808 - val_auc: 0.7767 - 158s/epoch - 158ms/step\n",
            "Epoch 20/200\n",
            "\n",
            "Epoch 20: saving model to ./cp_20_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5707 - auc: 0.7761 - val_loss: 0.5717 - val_auc: 0.7754 - 156s/epoch - 156ms/step\n",
            "Epoch 21/200\n",
            "\n",
            "Epoch 21: saving model to ./cp_21_.ckpt\n",
            "1000/1000 - 157s - loss: 0.5715 - auc: 0.7749 - val_loss: 0.5652 - val_auc: 0.7842 - 157s/epoch - 157ms/step\n",
            "Epoch 22/200\n",
            "\n",
            "Epoch 22: saving model to ./cp_22_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5647 - auc: 0.7816 - val_loss: 0.5621 - val_auc: 0.7852 - 156s/epoch - 156ms/step\n",
            "Epoch 23/200\n",
            "\n",
            "Epoch 23: saving model to ./cp_23_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5645 - auc: 0.7814 - val_loss: 0.5530 - val_auc: 0.7932 - 156s/epoch - 156ms/step\n",
            "Epoch 24/200\n",
            "\n",
            "Epoch 24: saving model to ./cp_24_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5574 - auc: 0.7883 - val_loss: 0.5588 - val_auc: 0.7869 - 156s/epoch - 156ms/step\n",
            "Epoch 25/200\n",
            "\n",
            "Epoch 25: saving model to ./cp_25_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5542 - auc: 0.7914 - val_loss: 0.5547 - val_auc: 0.7907 - 158s/epoch - 158ms/step\n",
            "Epoch 26/200\n",
            "\n",
            "Epoch 26: saving model to ./cp_26_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5575 - auc: 0.7881 - val_loss: 0.5565 - val_auc: 0.7898 - 159s/epoch - 159ms/step\n",
            "Epoch 27/200\n",
            "\n",
            "Epoch 27: saving model to ./cp_27_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5539 - auc: 0.7916 - val_loss: 0.5549 - val_auc: 0.7908 - 156s/epoch - 156ms/step\n",
            "Epoch 28/200\n",
            "\n",
            "Epoch 28: saving model to ./cp_28_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5580 - auc: 0.7881 - val_loss: 0.5626 - val_auc: 0.7849 - 156s/epoch - 156ms/step\n",
            "Epoch 29/200\n",
            "\n",
            "Epoch 29: saving model to ./cp_29_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5588 - auc: 0.7876 - val_loss: 0.5627 - val_auc: 0.7862 - 158s/epoch - 158ms/step\n",
            "Epoch 30/200\n",
            "\n",
            "Epoch 30: saving model to ./cp_30_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5586 - auc: 0.7873 - val_loss: 0.5572 - val_auc: 0.7890 - 156s/epoch - 156ms/step\n",
            "Epoch 31/200\n",
            "\n",
            "Epoch 31: saving model to ./cp_31_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5602 - auc: 0.7857 - val_loss: 0.5570 - val_auc: 0.7912 - 158s/epoch - 158ms/step\n",
            "Epoch 32/200\n",
            "\n",
            "Epoch 32: saving model to ./cp_32_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5587 - auc: 0.7869 - val_loss: 0.5541 - val_auc: 0.7921 - 158s/epoch - 158ms/step\n",
            "Epoch 33/200\n",
            "\n",
            "Epoch 33: saving model to ./cp_33_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5547 - auc: 0.7911 - val_loss: 0.5555 - val_auc: 0.7919 - 158s/epoch - 158ms/step\n",
            "Epoch 34/200\n",
            "\n",
            "Epoch 34: saving model to ./cp_34_.ckpt\n",
            "1000/1000 - 157s - loss: 0.5527 - auc: 0.7930 - val_loss: 0.5572 - val_auc: 0.7891 - 157s/epoch - 157ms/step\n",
            "Epoch 35/200\n",
            "\n",
            "Epoch 35: saving model to ./cp_35_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5524 - auc: 0.7930 - val_loss: 0.5529 - val_auc: 0.7926 - 156s/epoch - 156ms/step\n",
            "Epoch 36/200\n",
            "\n",
            "Epoch 36: saving model to ./cp_36_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5487 - auc: 0.7959 - val_loss: 0.5509 - val_auc: 0.7943 - 156s/epoch - 156ms/step\n",
            "Epoch 37/200\n",
            "\n",
            "Epoch 37: saving model to ./cp_37_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5520 - auc: 0.7928 - val_loss: 0.5479 - val_auc: 0.7975 - 156s/epoch - 156ms/step\n",
            "Epoch 38/200\n",
            "\n",
            "Epoch 38: saving model to ./cp_38_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5468 - auc: 0.7980 - val_loss: 0.5563 - val_auc: 0.7899 - 156s/epoch - 156ms/step\n",
            "Epoch 39/200\n",
            "\n",
            "Epoch 39: saving model to ./cp_39_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5521 - auc: 0.7932 - val_loss: 0.5527 - val_auc: 0.7935 - 158s/epoch - 158ms/step\n",
            "Epoch 40/200\n",
            "\n",
            "Epoch 40: saving model to ./cp_40_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5531 - auc: 0.7924 - val_loss: 0.5541 - val_auc: 0.7916 - 159s/epoch - 159ms/step\n",
            "Epoch 41/200\n",
            "\n",
            "Epoch 41: saving model to ./cp_41_.ckpt\n",
            "1000/1000 - 157s - loss: 0.5504 - auc: 0.7946 - val_loss: 0.5541 - val_auc: 0.7928 - 157s/epoch - 157ms/step\n",
            "Epoch 42/200\n",
            "\n",
            "Epoch 42: saving model to ./cp_42_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5518 - auc: 0.7939 - val_loss: 0.5532 - val_auc: 0.7948 - 158s/epoch - 158ms/step\n",
            "Epoch 43/200\n",
            "\n",
            "Epoch 43: saving model to ./cp_43_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5531 - auc: 0.7925 - val_loss: 0.5516 - val_auc: 0.7958 - 159s/epoch - 159ms/step\n",
            "Epoch 44/200\n",
            "\n",
            "Epoch 44: saving model to ./cp_44_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5525 - auc: 0.7929 - val_loss: 0.5534 - val_auc: 0.7929 - 158s/epoch - 158ms/step\n",
            "Epoch 45/200\n",
            "\n",
            "Epoch 45: saving model to ./cp_45_.ckpt\n",
            "1000/1000 - 157s - loss: 0.5509 - auc: 0.7945 - val_loss: 0.5545 - val_auc: 0.7931 - 157s/epoch - 157ms/step\n",
            "Epoch 46/200\n",
            "\n",
            "Epoch 46: saving model to ./cp_46_.ckpt\n",
            "1000/1000 - 159s - loss: 0.5507 - auc: 0.7947 - val_loss: 0.5543 - val_auc: 0.7911 - 159s/epoch - 159ms/step\n",
            "Epoch 47/200\n",
            "\n",
            "Epoch 47: saving model to ./cp_47_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5495 - auc: 0.7956 - val_loss: 0.5500 - val_auc: 0.7955 - 158s/epoch - 158ms/step\n",
            "Epoch 48/200\n",
            "\n",
            "Epoch 48: saving model to ./cp_48_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5475 - auc: 0.7975 - val_loss: 0.5506 - val_auc: 0.7945 - 158s/epoch - 158ms/step\n",
            "Epoch 49/200\n",
            "\n",
            "Epoch 49: saving model to ./cp_49_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5488 - auc: 0.7960 - val_loss: 0.5479 - val_auc: 0.7971 - 156s/epoch - 156ms/step\n",
            "Epoch 50/200\n",
            "\n",
            "Epoch 50: saving model to ./cp_50_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5477 - auc: 0.7971 - val_loss: 0.5465 - val_auc: 0.7984 - 158s/epoch - 158ms/step\n",
            "Epoch 51/200\n",
            "\n",
            "Epoch 51: saving model to ./cp_51_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5491 - auc: 0.7959 - val_loss: 0.5514 - val_auc: 0.7943 - 156s/epoch - 156ms/step\n",
            "Epoch 52/200\n",
            "\n",
            "Epoch 52: saving model to ./cp_52_.ckpt\n",
            "1000/1000 - 157s - loss: 0.5468 - auc: 0.7982 - val_loss: 0.5508 - val_auc: 0.7948 - 157s/epoch - 157ms/step\n",
            "Epoch 53/200\n",
            "\n",
            "Epoch 53: saving model to ./cp_53_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5454 - auc: 0.7994 - val_loss: 0.5488 - val_auc: 0.7971 - 158s/epoch - 158ms/step\n",
            "Epoch 54/200\n",
            "\n",
            "Epoch 54: saving model to ./cp_54_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5463 - auc: 0.7988 - val_loss: 0.5438 - val_auc: 0.8014 - 156s/epoch - 156ms/step\n",
            "Epoch 55/200\n",
            "\n",
            "Epoch 55: saving model to ./cp_55_.ckpt\n",
            "1000/1000 - 155s - loss: 0.5542 - auc: 0.7914 - val_loss: 0.5488 - val_auc: 0.7969 - 155s/epoch - 155ms/step\n",
            "Epoch 56/200\n",
            "\n",
            "Epoch 56: saving model to ./cp_56_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5476 - auc: 0.7974 - val_loss: 0.5503 - val_auc: 0.7951 - 156s/epoch - 156ms/step\n",
            "Epoch 57/200\n",
            "\n",
            "Epoch 57: saving model to ./cp_57_.ckpt\n",
            "1000/1000 - 155s - loss: 0.5516 - auc: 0.7936 - val_loss: 0.5472 - val_auc: 0.7980 - 155s/epoch - 155ms/step\n",
            "Epoch 58/200\n",
            "\n",
            "Epoch 58: saving model to ./cp_58_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5485 - auc: 0.7964 - val_loss: 0.5515 - val_auc: 0.7939 - 158s/epoch - 158ms/step\n",
            "Epoch 59/200\n",
            "\n",
            "Epoch 59: saving model to ./cp_59_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5451 - auc: 0.7992 - val_loss: 0.5567 - val_auc: 0.7886 - 158s/epoch - 158ms/step\n",
            "Epoch 60/200\n",
            "\n",
            "Epoch 60: saving model to ./cp_60_.ckpt\n",
            "1000/1000 - 158s - loss: 0.5488 - auc: 0.7964 - val_loss: 0.5495 - val_auc: 0.7955 - 158s/epoch - 158ms/step\n",
            "Epoch 61/200\n",
            "\n",
            "Epoch 61: saving model to ./cp_61_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5470 - auc: 0.7977 - val_loss: 0.5458 - val_auc: 0.7988 - 156s/epoch - 156ms/step\n",
            "Epoch 62/200\n",
            "\n",
            "Epoch 62: saving model to ./cp_62_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5462 - auc: 0.7989 - val_loss: 0.5487 - val_auc: 0.7968 - 156s/epoch - 156ms/step\n",
            "Epoch 63/200\n",
            "\n",
            "Epoch 63: saving model to ./cp_63_.ckpt\n",
            "1000/1000 - 156s - loss: 0.5457 - auc: 0.7992 - val_loss: 0.5479 - val_auc: 0.7980 - 156s/epoch - 156ms/step\n",
            "Epoch 64/200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame.from_dict(history.history).to_csv('history.csv',index=False)"
      ],
      "metadata": {
        "id": "qrKKviOlhfHI"
      },
      "id": "qrKKviOlhfHI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = pd.read_csv(\"./History.csv\")"
      ],
      "metadata": {
        "id": "6mNpoUkGhoX7"
      },
      "id": "6mNpoUkGhoX7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.array(range(0,200)), np.array(history[\"loss\"]) , label = \"Training\")\n",
        "plt.plot(np.array(range(0,200)), np.array(history[\"val_loss\"]) , label = \"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Validation and Training loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6bOZHfk8hriZ"
      },
      "id": "6bOZHfk8hriZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.array(range(0,200)), np.array(history[\"auc\"]) , label = \"Training\")\n",
        "plt.plot(np.array(range(0,200)), np.array(history[\"val_auc\"]) , label = \"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.title(\"Validation and Training AUC\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A9Gks8TMhtfB"
      },
      "id": "A9Gks8TMhtfB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step = np.arange(0, 200 * 1000)\n",
        "lr = cyclical_learning_rate(step)\n",
        "plt.plot(step, lr)\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Learning Rate\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_rjdWkZThvfj"
      },
      "id": "_rjdWkZThvfj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Z5EjzsRaVZJd",
        "zEXsjkfhVuzZ"
      ],
      "name": "QG_SACAMPBELL-Rev1-AddedKeras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ce1a6659239746298055606295f17184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3eeaab198774ab098dbe00bce553da0",
              "IPY_MODEL_12289f7518d841868b12574219a6671c",
              "IPY_MODEL_1447d20c1b684e579fa25b2c526eb126"
            ],
            "layout": "IPY_MODEL_4dbda994984f47b2b212806610042426"
          }
        },
        "e3eeaab198774ab098dbe00bce553da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf4b36fc3c24f76a35db489a4b2e096",
            "placeholder": "​",
            "style": "IPY_MODEL_3e28555b9bcc43a687ed792be71eaac2",
            "value": "100%"
          }
        },
        "12289f7518d841868b12574219a6671c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c4e81bddeb4ac4a368fc00a02111de",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46be4aba70ff467aaae6edaeb3c4f76d",
            "value": 46830571
          }
        },
        "1447d20c1b684e579fa25b2c526eb126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d29be7de00445494c1592bfaa46b06",
            "placeholder": "​",
            "style": "IPY_MODEL_f260d32ed54941fc9108166d62800f7c",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 157MB/s]"
          }
        },
        "4dbda994984f47b2b212806610042426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edf4b36fc3c24f76a35db489a4b2e096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e28555b9bcc43a687ed792be71eaac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c4e81bddeb4ac4a368fc00a02111de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46be4aba70ff467aaae6edaeb3c4f76d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96d29be7de00445494c1592bfaa46b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f260d32ed54941fc9108166d62800f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}