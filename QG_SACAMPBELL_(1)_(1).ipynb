{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Extract Data\n"
      ],
      "metadata": {
        "id": "Z5EjzsRaVZJd"
      },
      "id": "Z5EjzsRaVZJd"
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir data/"
      ],
      "metadata": {
        "id": "Rp0T0PqlVibO"
      },
      "id": "Rp0T0PqlVibO",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cernbox.cern.ch/index.php/s/ZUHveJKajnZNwTA/download -O data/ZUHveJKajnZNwTA.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoJ-0K4YVljT",
        "outputId": "a0bcf5d5-a91e-43f6-e690-f0a3bfb46d33"
      },
      "id": "hoJ-0K4YVljT",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-07 02:21:41--  https://cernbox.cern.ch/index.php/s/ZUHveJKajnZNwTA/download\n",
            "Resolving cernbox.cern.ch (cernbox.cern.ch)... 128.142.53.35, 137.138.120.151, 128.142.53.28, ...\n",
            "Connecting to cernbox.cern.ch (cernbox.cern.ch)|128.142.53.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘data/ZUHveJKajnZNwTA.tar’\n",
            "\n",
            "data/ZUHveJKajnZNwT     [        <=>         ]   4.51G  81.3MB/s    in 61s     \n",
            "\n",
            "2022-08-07 02:22:43 (76.2 MB/s) - ‘data/ZUHveJKajnZNwTA.tar’ saved [4848198144]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc2hT4B0VnnR",
        "outputId": "8df961b9-e5f9-406b-e21e-b2126684e048"
      },
      "id": "nc2hT4B0VnnR",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "my_tar = tarfile.open('ZUHveJKajnZNwTA.tar')\n",
        "my_tar.extractall('./data') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "metadata": {
        "id": "48r6j4jkVpcu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "dbdb1f28-bc29-471c-9b5f-d7bfd7fe2c4c"
      },
      "id": "48r6j4jkVpcu",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ReadError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReadError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-77da857a22b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ZUHveJKajnZNwTA.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmy_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# specify which folder to extract to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmy_tar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1578\u001b[0m                         \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file could not be opened successfully\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadError\u001b[0m: file could not be opened successfully"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data"
      ],
      "metadata": {
        "id": "TNw5kR0eVrxB"
      },
      "id": "TNw5kR0eVrxB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Data Into Images\n"
      ],
      "metadata": {
        "id": "zEXsjkfhVuzZ"
      },
      "id": "zEXsjkfhVuzZ"
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1g_anrPXNsM",
        "outputId": "dc4b18f6-ef54-4166-93dc-fb007f093283"
      },
      "id": "-1g_anrPXNsM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pyarrow.parquet as pq\n",
        "import os\n",
        "import time as time\n",
        "import PIL.Image as imm\n",
        "path = \"/content/data\"\n",
        "import cv2"
      ],
      "metadata": {
        "id": "X_OfCwq3Vzqd"
      },
      "id": "X_OfCwq3Vzqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"./Images/0\")\n",
        "os.makedirs(\"./Images/1\")"
      ],
      "metadata": {
        "id": "Jpr7DOo-o46P"
      },
      "id": "Jpr7DOo-o46P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(pf):\n",
        "    record_batch = pf.iter_batches(batch_size=1024)\n",
        "    while(True):\n",
        "        try:\n",
        "            batch = next(record_batch)\n",
        "            print(batch.num_rows)\n",
        "            transform(batch)\n",
        "        except StopIteration:\n",
        "            print(\"Done\")\n",
        "            break"
      ],
      "metadata": {
        "id": "FxAJxUQpV3h4"
      },
      "id": "FxAJxUQpV3h4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0\n",
        "beta =  0\n",
        "def saver(im,meta):\n",
        "    global alpha\n",
        "    global beta\n",
        "    for i in range(meta.shape[0]):\n",
        "        img = im[i,:,:,:]\n",
        "        img = img.T\n",
        "        img[:,:,0] = ( img[:,:,0] - img[:,:,0].min() ) / ( img[:,:,0].max()-img[:,:,0].min() )\n",
        "        img[:,:,1] = ( img[:,:,1] - img[:,:,1].min() ) / ( img[:,:,1].max()-img[:,:,1].min() )\n",
        "        img[:,:,2] = ( img[:,:,2] - img[:,:,2].min() ) / ( img[:,:,2].max()-img[:,:,2].min() )\n",
        "        img = img*255\n",
        "        img = img.astype(np.uint8)\n",
        "        #lmm = imm.fromarray(img)\n",
        "        if(meta[i] == 0):\n",
        "            impath = path+\"1/\"+str(alpha)+\".png\"\n",
        "            alpha = alpha + 1\n",
        "        if(meta[i] == 1):\n",
        "            impath = path+\"0/\"+str(beta)+\".png\"\n",
        "            beta = beta + 1\n",
        "        #lmm.save(impath)\n",
        "        cv2.imwrite(impath , img)"
      ],
      "metadata": {
        "id": "APW54ZLwV4Tb"
      },
      "id": "APW54ZLwV4Tb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(batch):\n",
        "    p = batch.to_pandas()\n",
        "    im = np.array(np.array(np.array(p.iloc[:,0].tolist()).tolist()).tolist())\n",
        "    meta = np.array(p.iloc[:,3])\n",
        "    saver(im,meta)"
      ],
      "metadata": {
        "id": "K4G0x9hJV6-O"
      },
      "id": "K4G0x9hJV6-O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(pq.ParquetFile(\"QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet\"))\n",
        "generate(pq.ParquetFile(\"QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet\"))\n",
        "generate(pq.ParquetFile(\"QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWRGrCwnV81B",
        "outputId": "ed77770d-33dd-4fb1-e5ec-84b424016f56"
      },
      "id": "nWRGrCwnV81B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "432\n",
            "Done\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "436\n",
            "Done\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "1024\n",
            "198\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing (Pytorch)"
      ],
      "metadata": {
        "id": "7FUx_y3sWB2X"
      },
      "id": "7FUx_y3sWB2X"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "import os, glob\n",
        "import time\n",
        "import h5py\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import ConcatDataset, Dataset, DataLoader, sampler, DistributedSampler\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import *\n",
        "import numpy\n",
        "import time\n",
        "import h5py\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import math \n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "x5yINiGOWHcF"
      },
      "id": "x5yINiGOWHcF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParquetDataset(Dataset):\n",
        "    def __init__(self, filename, transform=None):\n",
        "        self.parquet = pq.ParquetFile(filename)\n",
        "        self.cols = None \n",
        "        self.transform = transform\n",
        "    def __getitem__(self, index):\n",
        "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
        "        # Preprocessing\n",
        "        start = time.time()\n",
        "        data['X_jets'] = np.float32(data['X_jets'])\n",
        "        data['X_jets'] = torch.Tensor(data['X_jets'])\n",
        "        data['y'] = torch.Tensor(data['y'])\n",
        "        \n",
        "        #to preprocess\n",
        "        data['X_jets'][data['X_jets'] < 1.e-3] = 0. # Zero-Suppression\n",
        "        data['X_jets'][-1,...] = 25.*data['X_jets'][-1,...] # For HCAL: to match pixel intensity distn of other layers\n",
        "        data['X_jets'] = data['X_jets']/100. # To standardize\n",
        "        #data['X'] = np.float32(data['X'][0])\n",
        "        #print(\"List lenth\",data['X_jets'])\n",
        "        #data['X_jets'] = numpy.array(data['X_jets'])\n",
        "        \n",
        "        if self.transform:\n",
        "            #data['X_jets'] = numpy.moveaxis(data['X_jets'], 1,3)\n",
        "            #print(\"Trnsforn : \",data['X_jets'].shape)\n",
        "            data['X_jets']= self.transform(data['X_jets'][0]) \n",
        "        #data['X_jets'] = numpy.moveaxis(data['X_jets'], -1,1)\n",
        "        \n",
        "        #print(\"Lter : \",data['X_jets'].shape)\n",
        "        \n",
        "        end = time.time()\n",
        "        #print(\"Time required for preprocessing : \",end - start)\n",
        "        \n",
        "        #print(\"Mean : \", torch.mean(data['X_jets']))\n",
        "        return dict(data)\n",
        "    def __len__(self):\n",
        "        return self.parquet.num_row_groups"
      ],
      "metadata": {
        "id": "PrY-TMYiWKrn"
      },
      "id": "PrY-TMYiWKrn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "def get_data_loader(datasets, batch_size, cut, random_sampler=False):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.RandomRotation(20)\n",
        "    ])\n",
        "    #scripted_transforms = torch.jit.script(transforms)\n",
        "  \n",
        "    dset = ConcatDataset([ParquetDataset(dataset, transform=transform) for dataset in datasets])\n",
        "    idxs = np.random.permutation(len(dset))\n",
        "    if random_sampler: \n",
        "        random_sampler = sampler.SubsetRandomSampler(idxs[:cut])\n",
        "    else: \n",
        "        random_sampler = None \n",
        "    validation_split = .2\n",
        "    shuffle_dataset = True\n",
        "    random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "    dataset_size = 55494\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(validation_split * dataset_size))\n",
        "    print(split)\n",
        "    if shuffle_dataset :\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "    train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(val_indices)\n",
        "    print(\"Train indices \",train_sampler)\n",
        "    print(\"Test indices \", valid_sampler)\n",
        "    train_loader = torch.utils.data.DataLoader(dset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler)\n",
        "    test_loader = torch.utils.data.DataLoader(dset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler)\n",
        "    \n",
        "    #data_loader = DataLoader(dataset=dset, batch_size=batch_size, shuffle=False, num_workers=10, sampler=random_sampler, pin_memory=True)\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "uDvXzHzrWOSw"
      },
      "id": "uDvXzHzrWOSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets_train = ['QCDToGGQQ_IMGjet_RH1all_jet0_run0_n215556.train.snappy.parquet', \n",
        "                  'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n297980.train.snappy.parquet', \n",
        "                  'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n280364.train.snappy.parquet']\n",
        "datasets_test = ['QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet',\n",
        "                 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet',\n",
        "                 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet']"
      ],
      "metadata": {
        "id": "BQyNDvVZWSCN"
      },
      "id": "BQyNDvVZWSCN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data/data"
      ],
      "metadata": {
        "id": "6oznZGn2WUTJ"
      },
      "id": "6oznZGn2WUTJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader= get_data_loader(datasets_train, 32, cut = None, random_sampler = True)\n",
        "#test_loader = get_data_loader(datasets_test, 32, cut = None, random_sampler = True)"
      ],
      "metadata": {
        "id": "QjUd39UUWWkk"
      },
      "id": "QjUd39UUWWkk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, batch in enumerate(train_loader):\n",
        "    X_jets,\tpt,\tm0,\ty = batch[\"X_jets\"], batch[\"pt\"], batch[\"m0\"],batch[\"y\"]\n",
        "    #print(torch.max(X_jets))\n",
        "    if (i%50 ==0):\n",
        "        print(torch.max(X_jets))"
      ],
      "metadata": {
        "id": "kiPOpwQMWZCy"
      },
      "id": "kiPOpwQMWZCy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_collate(batch):\n",
        "    data = torch.cat([item[0] for item in batch],dim = 0)\n",
        "    target = torch.cat([item[1] for item in batch],dim = 0)\n",
        "\n",
        "    return [data, target]"
      ],
      "metadata": {
        "id": "8vTQTkDMWbg7"
      },
      "id": "8vTQTkDMWbg7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, data_loader, loss_history):\n",
        "    total_samples = len(data_loader)*32 #batch size =32\n",
        "    correct_samples = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i, batch in enumerate(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data = batch[\"X_jets\"]\n",
        "        data = data.cuda()\n",
        "        output = model(data)\n",
        "        target = batch[\"y\"]\n",
        "        target = target.cuda()\n",
        "        target = torch.squeeze(target, dim=1)\n",
        "        loss = nn.BCEWithLogitsLoss()(torch.squeeze(output, dim=1),target)\n",
        "        pred = torch.squeeze(nn.Sigmoid()(output))\n",
        "        pred[pred>=0.5] = 1\n",
        "        pred[pred<0.5] = 0\n",
        "        optimizer.step()\n",
        "        \n",
        "        correct_samples += pred.eq(target).sum()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('[' +  '{:5}'.format(i * len(data)) + '/' + '{:5}'.format(total_samples) +\n",
        "                  ' (' + '{:3.0f}'.format(100 * i / len(data_loader)) + '%)]  Loss: ' +\n",
        "                  '{:6.4f}'.format(loss.item()) + '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "                  '{:5}'.format(total_samples) + ' (' + '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)')\n",
        "            loss_history.append(loss.item())"
      ],
      "metadata": {
        "id": "og7QEi3fWd6R"
      },
      "id": "og7QEi3fWd6R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, loss_history):\n",
        "    model.eval()\n",
        "    \n",
        "    total_samples = len(data_loader)*32 #len(data_loader.dataset)\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            \n",
        "            data = batch[\"X_jets\"]\n",
        "            data = data.cuda()\n",
        "            output = model(data)\n",
        "            target = batch[\"y\"]\n",
        "            target = target.cuda()\n",
        "            target = torch.squeeze(target, dim=1)\n",
        "            loss = nn.BCEWithLogitsLoss()(torch.squeeze(output, dim=1),target)\n",
        "            pred = torch.squeeze(nn.Sigmoid()(output))\n",
        "            pred[pred>=0.5] = 1\n",
        "            pred[pred<0.5] = 0\n",
        "            total_loss += loss.item()\n",
        "            correct_samples += pred.eq(target).sum()\n",
        "\n",
        "    avg_loss = total_loss / (total_samples/32)\n",
        "    loss_history.append(avg_loss) \n",
        "    print('\\nAverage val loss: ' + '{:.4f}'.format(avg_loss) +\n",
        "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "          '{:5}'.format(total_samples) + ' (' +\n",
        "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')"
      ],
      "metadata": {
        "id": "OeybrbsoWgu9"
      },
      "id": "OeybrbsoWgu9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection, Training, and Evaluation (Pytorch)"
      ],
      "metadata": {
        "id": "BThw1UXQWlgc"
      },
      "id": "BThw1UXQWlgc"
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torchvision\n",
        "from torchvision.models import ResNet18_Weights\n",
        "torchvision.models.ResNet18_Weights(ResNet18_Weights.DEFAULT)\n",
        "#resnet18 = models.resnet18(weights='IMAGENET1K_V1')\n",
        "resnet18 = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "id": "3MvNm9XHWrna"
      },
      "id": "3MvNm9XHWrna",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 8\n",
        "import time\n",
        "start_time = time.time()\n",
        "from torch import nn\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "model = resnet18\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "model.fc = nn.Sequential(nn.AdaptiveAvgPool1d(512),\n",
        "                         nn.Dropout(0.3),\n",
        "                         nn.Linear(512,256),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(0.3),\n",
        "                         nn.Linear(256,1),\n",
        "                         nn.Sigmoid())\n",
        "model.cuda()\n",
        "\n",
        "cnt = 0\n",
        "train_loss_history, test_loss_history = [], []\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    \n",
        "    r = 0.0005/(10**(cnt))\n",
        "    print(\"LR:\",r)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=r)\n",
        "    print('Epoch:', epoch)\n",
        "    train_epoch(model, optimizer, train_loader, train_loss_history)\n",
        "    print(\"Training done!\")\n",
        "    evaluate(model, test_loader, test_loss_history)\n",
        "    pred_list, target_list = evaluate(model, test_loader, test_loss_history)\n",
        "    fpr, tpr, _ = roc_curve(target_list, pred_list)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print('Training ROC AUC:', roc_auc)\n",
        "    if epoch%4==0:\n",
        "      cnt=cnt+1\n",
        "    \n",
        "\n",
        "print('Execution time:', '{:5.2f}'.format(time.time() - start_time), 'seconds')"
      ],
      "metadata": {
        "id": "QZvd6QBKWtjG"
      },
      "id": "QZvd6QBKWtjG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader, loss_history):\n",
        "    model.eval()\n",
        "    pred_list = []\n",
        "    target_list = []\n",
        "    total_samples = len(data_loader)*32\n",
        "    correct_samples = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            \n",
        "            data = batch[\"X_jets\"]\n",
        "            data = data.cuda()\n",
        "            output = model(data)\n",
        "            target = batch[\"y\"]\n",
        "            target = target.cuda()          \n",
        "            target = torch.squeeze(target, dim=1)\n",
        "            loss = nn.BCEWithLogitsLoss()(torch.squeeze(output, dim=1),target)\n",
        "            pred = torch.squeeze(nn.Sigmoid()(output))\n",
        "            pred_list.extend(pred.tolist())\n",
        "            target_list.extend(target.tolist())\n",
        "            pred[pred>=0.5] = 1\n",
        "            pred[pred<0.5] = 0\n",
        "            total_loss += loss.item()\n",
        "            correct_samples += pred.eq(target).sum()\n",
        "\n",
        "    avg_loss = total_loss / (total_samples/32)\n",
        "    loss_history.append(avg_loss)\n",
        "    print('\\nAverage test loss: ' + '{:.4f}'.format(avg_loss) +\n",
        "          '  Accuracy:' + '{:5}'.format(correct_samples) + '/' +\n",
        "          '{:5}'.format(total_samples) + ' (' +\n",
        "          '{:4.2f}'.format(100.0 * correct_samples / total_samples) + '%)\\n')\n",
        "    return pred_list,target_list"
      ],
      "metadata": {
        "id": "C2jeaeyQWwbw"
      },
      "id": "C2jeaeyQWwbw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_history = []\n",
        "pred_list, target_list = test(model, test_loader, test_loss_history)"
      ],
      "metadata": {
        "id": "uu2vdXGOWzSO"
      },
      "id": "uu2vdXGOWzSO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, _ = roc_curve(target_list, pred_list)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "print('Test ROC AUC:', roc_auc)"
      ],
      "metadata": {
        "id": "zkxxb4ogW1Zj"
      },
      "id": "zkxxb4ogW1Zj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "#plt.legend(loc=2, prop={'size': 15})\n",
        "plt.plot(fpr, tpr, label='Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve: Resnet 18 (modified FC Layer)')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "plt.savefig('resnet_18_ROC_modified.png')"
      ],
      "metadata": {
        "id": "NFvTkvvbW3eg"
      },
      "id": "NFvTkvvbW3eg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Preprocessing (Keras)"
      ],
      "metadata": {
        "id": "f2uyQcawIcNV"
      },
      "id": "f2uyQcawIcNV"
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/data/data"
      ],
      "metadata": {
        "id": "3yrHGeWJI8Jt"
      },
      "id": "3yrHGeWJI8Jt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import PIL.Image as im\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "WByx0OeYIo2g"
      },
      "id": "WByx0OeYIo2g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen= ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split = 0.2\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/kaggle/input/cmscommon2/Images',\n",
        "        target_size= (125,125),\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "        shuffle = True\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        '/kaggle/input/cmscommon2/Images',\n",
        "        target_size= (125,125),\n",
        "        color_mode='rgb',\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation',\n",
        "        shuffle = True\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "NpAFd6gqIsbO"
      },
      "id": "NpAFd6gqIsbO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Z5EjzsRaVZJd",
        "zEXsjkfhVuzZ"
      ],
      "name": "QG_SACAMPBELL_(1) (1).ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}